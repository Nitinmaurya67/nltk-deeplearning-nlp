{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bfd3716-f1a4-42ef-87df-a31deefd81ec",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 46px; font-weight: bold;\">\n",
    "NLP : Natural Language Processing \n",
    "</h1>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daef68d4-5102-40a3-bd96-1e33623cc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"GeeksforGeeks is a great learning platform . It is one of the best for Computer Science students.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718042c4-18ef-4286-87e8-e08ed91df0c8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 40px; font-weight: bold;\">\n",
    "Tokenization\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color:#B0C4DE; font-family: 'Trebuchet MS', sans-serif; font-size: 22px;\">\n",
    "Tokenization is the process of splitting text into smaller pieces called tokens, such as words or sentences.\n",
    "</h3>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## What Is Tokenization?\n",
    "\n",
    "Tokenization breaks text into manageable parts for NLP tasks.  \n",
    "\n",
    "**Example Sentence:**  \n",
    "*\"Natural Language Processing is amazing!\"*\n",
    "\n",
    "**Word Tokens:**  \n",
    "[\"Natural\", \"Language\", \"Processing\", \"is\", \"amazing\", \"!\"]\n",
    "\n",
    "**Sentence Tokens:**  \n",
    "[\"Natural Language Processing is amazing!\"]\n",
    "\n",
    "---\n",
    "\n",
    "## Why Use Tokenization?\n",
    "\n",
    "- Helps analyze text **word by word or sentence by sentence**  \n",
    "- Necessary for **text preprocessing** steps like stop word removal, stemming, or lemmatization  \n",
    "- Forms the foundation for **N-grams, Count Vectorizer, and other NLP techniques**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d85b1526-be17-4f21-9b69-f2d753c219b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6439fee9-3bc8-44dd-9b0d-71b31ea209d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GeeksforGeeks',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'learning',\n",
       " 'platform',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'best',\n",
       " 'for',\n",
       " 'Computer',\n",
       " 'Science',\n",
       " 'students',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e0a8ea-7a87-4ace-b1e5-f60c01e94bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GeeksforGeeks is a great learning platform .',\n",
       " 'It is one of the best for Computer Science students.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a113891-432d-4dd8-a283-4a83fed5619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58623a03-6cba-49ff-9274-32bd55be6b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GeeksforGeeks', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('learning', 'JJ'),\n",
       " ('platform', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('for', 'IN'),\n",
       " ('Computer', 'NNP'),\n",
       " ('Science', 'NNP'),\n",
       " ('students', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc1030-985b-4979-a36c-1fe14dd325c3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 40px; font-weight: bold;\">\n",
    "Stop Words\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color:#B0C4DE; font-family: 'Trebuchet MS', sans-serif; font-size: 22px;\">\n",
    "Stop Words are common words in a language that do not add significant meaning to text and can be removed for NLP tasks.\n",
    "</h3>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## What Are Stop Words?\n",
    "\n",
    "Stop words are words like **\"a\", \"an\", \"the\", \"is\", \"in\"** that appear frequently but carry little information.\n",
    "\n",
    "**Example Sentence:**  \n",
    "*\"This is a simple example of NLP in action.\"*\n",
    "\n",
    "**After removing stop words:**  \n",
    "*\"simple example NLP action\"*\n",
    "\n",
    "---\n",
    "\n",
    "## Why Remove Stop Words?\n",
    "\n",
    "- Reduces **noise** in the text  \n",
    "- Speeds up **processing** and **analysis**  \n",
    "- Improves results in **text classification, sentiment analysis, and search engines**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8cb3ea4-e6f0-4dcd-8361-e64a591776c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef87bc0-f73e-4a4d-9b6e-1cb57e12b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nitin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "845aa5e0-ecbc-41b9-a7d2-7bb6523be5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop =stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3706bfe-cb81-4bc0-8b54-20cff9a70ffc",
   "metadata": {},
   "source": [
    "### punctuation : '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "925a1efe-8839-4021-8a0c-5a079f12f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(punctuation) + stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebcd0bf7-3e17-48be-ba05-7d2505a0a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeeksforGeeks\n",
      "great\n",
      "learning\n",
      "platform\n",
      "It\n",
      "one\n",
      "best\n",
      "Computer\n",
      "Science\n",
      "students\n"
     ]
    }
   ],
   "source": [
    "for i in word_tokenize(s) :\n",
    "    if i not in stop_words:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4152e590-c4dc-4f34-b33a-0b43f238479e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 40px; font-weight: bold;\">\n",
    "Stemming\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color:#B0C4DE; font-family: 'Trebuchet MS', sans-serif; font-size: 22px;\">\n",
    "Stemming in NLTK refers to the process of reducing words to their base or root form.\n",
    "</h3>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 🌟 Types of Stemmers in NLTK\n",
    "\n",
    "NLTK provides several algorithms for stemming. Here are the most popular ones:\n",
    "\n",
    "| Stemmer | Description |\n",
    "|---------|-------------|\n",
    "| **Porter Stemmer** | One of the oldest and most widely used stemming algorithms. Good for English words. |\n",
    "| **Lancaster Stemmer** | More aggressive than Porter; may produce shorter stems. |\n",
    "| **Snowball Stemmer** | An improved version of Porter Stemmer with support for multiple languages. |\n",
    "| **Regexp Stemmer** | Allows you to define custom regular expressions for stemming. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31ce40f8-8f29-4453-8c38-d6c0b492080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer , RegexpStemmer , PorterStemmer ,SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a967cc3-aabd-4230-8287-0ad913ebb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LancasterStemmer()\n",
    "r = RegexpStemmer('ing')\n",
    "p = PorterStemmer()\n",
    "s = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bcbd3bc-b54f-4437-afe3-b338bd3538c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lowest'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"changing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdc83b3b-bcb1-4d32-b028-fc4009e4d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.stem(\"changing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b95016a5-397d-43bb-ad1e-ad7680281d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stem(\"changes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faab9283-1917-42c2-8302-caa78f961ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b5879a-8615-492a-9ab3-848ccdce7140",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 40px; font-weight: bold;\">\n",
    "Lemmatization\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color:#B0C4DE; font-family: 'Trebuchet MS', sans-serif; font-size: 22px;\">\n",
    "Lemmatization reduces words to their base or dictionary form, considering meaning and context.\n",
    "</h3>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## WordNet Lemmatizer\n",
    "\n",
    "NLTK uses the **WordNet Lemmatizer** to find the base form of words.  \n",
    "It handles irregular forms and considers the context when needed.\n",
    "\n",
    "- **Example:** \"mice\" → \"mouse\", \"better\" → \"good\", \"flies\" → \"fly\"\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Difference Between Stemming and Lemmatization\n",
    "\n",
    "| Feature | Stemming | Lemmatization |\n",
    "|---------|----------|---------------|\n",
    "| **Definition** | Cuts words to their root form. | Converts words to their base/dictionary form using meaning. |\n",
    "| **Accuracy** | Less accurate; may not be real words. | More accurate; always valid words. |\n",
    "| **Example** | \"running\" → \"run\", \"flies\" → \"fli\" | \"mice\" → \"mouse\", \"better\" → \"good\" |\n",
    "| **Speed** | Faster | Slower |\n",
    "| **Use** | Quick preprocessing. | When meaning matters in NLP tasks. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4249565-cf90-4234-8955-d4158de5e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "106df68a-2d5f-4e07-a8ed-f7301fc47abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nitin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2d04cda-6528-4085-979f-98d9f6482ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mouse'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl = WordNetLemmatizer()\n",
    "wl.lemmatize(\"mice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bdf5e-4056-4845-b39f-6f9b5269cf5a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 40px; font-weight: bold;\">\n",
    "N-Grams\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color:#B0C4DE; font-family: 'Trebuchet MS', sans-serif; font-size: 22px;\">\n",
    "N-grams are groups of N words taken together from a sentence.\n",
    "</h3>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## What Are N-Grams?\n",
    "\n",
    "N-grams help in understanding word patterns and relationships in text.\n",
    "\n",
    "| Type | Example (from: \"I love natural language processing\") |\n",
    "|------|------------------------------------------------------|\n",
    "| **Unigram (1-word)** | I, love, natural, language, processing |\n",
    "| **Bigram (2-words)** | I love, love natural, natural language |\n",
    "| **Trigram (3-words)** | I love natural, love natural language |\n",
    "\n",
    "---\n",
    "\n",
    "## Why Use N-Grams?\n",
    "\n",
    "- To analyze **word combinations**\n",
    "- Useful in **text prediction** and **language modelling**\n",
    "- Commonly used in **chatbots, autocomplete, and spam detection**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57ea2897-a94c-4539-860a-ae4832fc601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder , TrigramCollocationFinder , ngrams \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e9c2169-0f77-49b1-816f-56ea0c9bafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"my name is nitin  i am a good boy i am a bca student.\"\n",
    "w = word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b450cc5c-da68-49a1-ba1f-4f4786c2ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BigramCollocationFinder.from_words(w)\n",
    "t = TrigramCollocationFinder.from_words(w)\n",
    "n = ngrams(w , 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d7056c75-8fe8-4eb5-bf40-0b12a2b98669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('i', 'am'): 2, ('am', 'a'): 2, ('my', 'name'): 1, ('name', 'is'): 1, ('is', 'nitin'): 1, ('nitin', 'i'): 1, ('a', 'good'): 1, ('good', 'boy'): 1, ('boy', 'i'): 1, ('a', 'bca'): 1, ...})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.ngram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67b28175-a61b-42f9-894b-7323d2115964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('i', 'am', 'a'): 2, ('my', 'name', 'is'): 1, ('name', 'is', 'nitin'): 1, ('is', 'nitin', 'i'): 1, ('nitin', 'i', 'am'): 1, ('am', 'a', 'good'): 1, ('a', 'good', 'boy'): 1, ('good', 'boy', 'i'): 1, ('boy', 'i', 'am'): 1, ('am', 'a', 'bca'): 1, ...})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.ngram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "824e32d7-5149-4432-b165-d26842854654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('my', 'name', 'is', 'nitin')\n",
      "('name', 'is', 'nitin', 'i')\n",
      "('is', 'nitin', 'i', 'am')\n",
      "('nitin', 'i', 'am', 'a')\n",
      "('i', 'am', 'a', 'good')\n",
      "('am', 'a', 'good', 'boy')\n",
      "('a', 'good', 'boy', 'i')\n",
      "('good', 'boy', 'i', 'am')\n",
      "('boy', 'i', 'am', 'a')\n",
      "('i', 'am', 'a', 'bca')\n",
      "('am', 'a', 'bca', 'student')\n",
      "('a', 'bca', 'student', '.')\n"
     ]
    }
   ],
   "source": [
    "for i in n :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2bd1f-df44-440a-bbde-073f961d2e6b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 40px; font-weight: bold;\">\n",
    "Count Vectorizer\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color:#B0C4DE; font-family: 'Trebuchet MS', sans-serif; font-size: 22px;\">\n",
    "Count Vectorizer converts text into numbers by counting how many times each word appears.\n",
    "</h3>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "Given the sentences:\n",
    "\n",
    "1. **\"One Geek helps Two Geeks\"**  \n",
    "2. **\"Two Geeks help Four Geeks\"**  \n",
    "3. **\"Each Geek helps many other Geeks at GeeksforGeeks.\"**\n",
    "\n",
    "Count Vectorizer will convert them into a table like this:\n",
    "\n",
    "| Word           | one | geek | helps | two | geeks | help | four | each | many | other | at | geeksforgeeks |\n",
    "|----------------|-----|------|-------|-----|-------|------|------|------|------|-------|----|---------------|\n",
    "| Sentence 1     | 1   | 1    | 1     | 1   | 1     | 0    | 0    | 0    | 0    | 0     | 0  | 0             |\n",
    "| Sentence 2     | 0   | 0    | 0     | 1   | 1     | 1    | 1    | 0    | 0    | 0     | 0  | 0             |\n",
    "| Sentence 3     | 0   | 1    | 1     | 0   | 1     | 0    | 0    | 1    | 1    | 1     | 1  | 1             |\n",
    "\n",
    "---\n",
    "\n",
    "## Why Use Count Vectorizer?\n",
    "\n",
    "- It **turns text into numbers**, which is necessary for **machine learning models**  \n",
    "- Commonly used in **text classification, spam detection, sentiment analysis**, etc.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70543852-0785-4f86-87a6-ef3cc9002957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ce1ac0a-4c3d-420f-8963-0aa6b2fd9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [ \"One Geek helps Two Geeks\", \"Two Geeks help Four Geeks\", \"Each Geek helps many other Geeks at GeeksforGeeks.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abb96459-f1e3-409f-87df-0934f0e0d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.DataFrame({\"name\":l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80166ea6-fb8b-4ec5-bdb7-b7d8c760a924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Geek helps Two Geeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two Geeks help Four Geeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Each Geek helps many other Geeks at GeeksforGe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name\n",
       "0                           One Geek helps Two Geeks\n",
       "1                          Two Geeks help Four Geeks\n",
       "2  Each Geek helps many other Geeks at GeeksforGe..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfa4937e-96f1-49a4-8963-69056eb3db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75f81370-96b7-433e-bf63-795f5d574afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57f0de75-aaa9-4a9f-95e1-c08ca4557fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = cv.fit_transform(df['name']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8369df5a-b7b1-4a6c-b350-698b3ce34b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4abb0bf3-0f82-4b0c-a3fc-d616c032d04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 9,\n",
       " 'geek': 3,\n",
       " 'helps': 7,\n",
       " 'two': 11,\n",
       " 'geeks': 4,\n",
       " 'help': 6,\n",
       " 'four': 2,\n",
       " 'each': 1,\n",
       " 'many': 8,\n",
       " 'other': 10,\n",
       " 'at': 0,\n",
       " 'geeksforgeeks': 5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a77c52-4d6f-40db-93b3-69bd41e69551",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<h1 style=\"color:#FFB84C; font-family: 'Georgia', serif; font-size: 40px; font-weight: bold;\">\n",
    "Word Sense Disambiguation (WSD)\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color:#B0C4DE; font-family: 'Trebuchet MS', sans-serif; font-size: 22px;\">\n",
    "WSD is the process of identifying the correct meaning of a word based on context.\n",
    "</h3>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## What Is Word Sense Disambiguation?\n",
    "\n",
    "Some words have multiple meanings. WSD helps the system understand **which meaning is correct** in a given sentence.\n",
    "\n",
    "| Word | Sentence | Meaning Chosen |\n",
    "|------|----------|----------------|\n",
    "| **Bank** | \"He sat by the river bank.\" | River side |\n",
    "| **Bank** | \"She deposited money in the bank.\" | Financial institution |\n",
    "| **Bat** | \"A bat flew in the night sky.\" | Animal |\n",
    "| **Bat** | \"He hit the ball with a bat.\" | Sports equipment |\n",
    "\n",
    "---\n",
    "\n",
    "## Why Use WSD?\n",
    "\n",
    "- Helps machines understand **context and meaning**\n",
    "- Useful in **translation, question answering, and chatbots**\n",
    "- Makes NLP systems **more intelligent and human-like**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab2e7a5-2bc0-48b4-8733-b83815ac78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56612459-ad9a-43aa-ab80-917c1e00a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"sun is glowing\"\n",
    "y = \"The girl nodded and brushed the loose strands of mouse brown hair from her face.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e7b5688-ee51-4d44-b792-43eb4f23b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lesk(word_tokenize(\"y\"),'sun')\n",
    "m = lesk(word_tokenize(\"x\"),'mouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "636fa34b-0dfd-4d13-bae6-121754314460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the star that is the source of light and heat for the planets in the solar system'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab668f1c-faea-4529-a78a-0812214309f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.definition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
